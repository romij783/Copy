<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>JARVIS X | NEURAL LIVE</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://unpkg.com/lucide@latest"></script>
    <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@400;700&family=Plus+Jakarta+Sans:wght@300;400;600&display=swap" rel="stylesheet">
    <style>
        :root { --neon: #00f2ff; --warn: #ff004c; --bg-dark: #020406; }
        body { font-family: 'Plus Jakarta Sans', sans-serif; background: var(--bg-dark); color: #e2e8f0; overflow: hidden; height: 100vh; }
        .orbitron { font-family: 'Orbitron', sans-serif; }
        
        /* Glassmorphism Design */
        .glass { background: rgba(8, 10, 15, 0.85); backdrop-filter: blur(20px); border: 1px solid rgba(255, 255, 255, 0.08); }
        .neon-glow { box-shadow: 0 0 20px rgba(0, 242, 255, 0.15); border: 1px solid rgba(0, 242, 255, 0.3); }
        
        /* Live Mode Animations */
        @keyframes pulse-ring { 0% { transform: scale(0.8); opacity: 0.5; } 100% { transform: scale(1.2); opacity: 0; } }
        .pulse-effect { position: absolute; border: 2px solid var(--neon); border-radius: 50%; animation: pulse-ring 2s infinite; }

        @keyframes wave { 0%, 100% { height: 10px; } 50% { height: 40px; } }
        .wave-bar { width: 4px; background: var(--neon); border-radius: 10px; animation: wave 1.2s infinite ease-in-out; }

        /* Camera Viewport */
        #live-video { width: 100%; height: 100%; object-fit: cover; filter: brightness(0.7) contrast(1.1); transition: 1s; }
        .live-active #live-video { filter: brightness(0.5) sepia(0.2) hue-rotate(160deg); }

        ::-webkit-scrollbar { width: 4px; }
        ::-webkit-scrollbar-thumb { background: #1e293b; border-radius: 10px; }
    </style>
</head>
<body class="flex flex-col">

    <!-- Header HUD -->
    <header class="h-16 glass border-b border-white/5 flex items-center justify-between px-6 z-50">
        <div class="flex items-center gap-3">
            <div class="w-8 h-8 rounded-lg bg-cyan-600 flex items-center justify-center neon-glow">
                <i data-lucide="zap" class="w-5 h-5 text-black"></i>
            </div>
            <h1 class="text-lg font-bold orbitron tracking-tighter text-cyan-400">JARVIS X</h1>
        </div>
        <div class="flex items-center gap-4 text-[10px] orbitron text-cyan-500">
            <span id="sys-pwr">PWR: 100%</span>
            <div class="h-2 w-2 rounded-full bg-green-500 animate-pulse"></div>
        </div>
    </header>

    <!-- Main Content Area -->
    <main class="flex-1 relative flex flex-col overflow-hidden">
        
        <!-- Chat Flow -->
        <div id="chat-container" class="flex-1 overflow-y-auto p-4 md:p-10 space-y-6 scroll-smooth pb-32">
            <div class="flex gap-4 max-w-2xl">
                <div class="w-10 h-10 rounded-xl bg-cyan-900/20 border border-cyan-500/20 flex items-center justify-center shrink-0">
                    <i data-lucide="bot" class="w-6 h-6 text-cyan-400"></i>
                </div>
                <div class="glass p-4 rounded-2xl rounded-tl-none text-sm border-white/5 shadow-xl">
                    Greetings, sir. Neural link is active. Shall we initiate live vision?
                </div>
            </div>
        </div>

        <!-- Floating Live Vision Button -->
        <button onclick="enterLiveMode()" id="live-btn" class="fixed bottom-28 right-6 w-16 h-16 bg-cyan-500 text-black rounded-full shadow-[0_0_30px_rgba(0,242,255,0.4)] flex items-center justify-center z-50 hover:scale-110 transition-transform">
            <i data-lucide="eye" class="w-8 h-8"></i>
        </button>

        <!-- Input Section -->
        <div class="absolute bottom-0 w-full p-4 md:p-8 glass border-t border-white/5 z-40">
            <div id="auth-section" class="max-w-4xl mx-auto flex gap-2 mb-2">
                <input type="password" id="api-key" placeholder="Enter OpenRouter API Key..." class="flex-1 bg-black/50 border border-white/10 rounded-xl px-4 py-3 text-xs outline-none focus:border-cyan-500">
                <button onclick="saveAuth()" class="px-6 py-3 bg-cyan-600 text-black font-bold text-xs orbitron rounded-xl">CHECK-IN</button>
            </div>

            <div id="input-section" class="max-w-4xl mx-auto relative hidden">
                <div class="flex items-center gap-2 glass p-2 rounded-2xl border-white/10 neon-glow">
                    <textarea id="user-input" rows="1" placeholder="Type or use voice..." class="flex-1 bg-transparent border-none outline-none text-sm p-3 resize-none max-h-32"></textarea>
                    <button onclick="startVoiceRec()" class="p-3 text-gray-400 hover:text-cyan-400"><i data-lucide="mic" class="w-6 h-6"></i></button>
                    <button onclick="handleSend()" class="p-3 bg-cyan-500 text-black rounded-xl hover:bg-cyan-300"><i data-lucide="send" class="w-6 h-6"></i></button>
                </div>
            </div>
        </div>
    </main>

    <!-- Gemini Live Style Full Overlay -->
    <div id="live-overlay" class="fixed inset-0 z-[100] bg-black hidden flex-col items-center justify-center p-6">
        <button onclick="exitLiveMode()" class="absolute top-10 right-10 text-gray-500 hover:text-white z-50"><i data-lucide="x-circle" class="w-10 h-10"></i></button>
        
        <!-- Live Camera Circle -->
        <div class="relative w-72 h-72 md:w-96 md:h-96 rounded-full overflow-hidden border-4 border-cyan-500/30 neon-glow mb-10 flex items-center justify-center">
            <video id="live-video" class="absolute inset-0" autoplay playsinline></video>
            <div id="vision-scanner" class="absolute inset-0 pointer-events-none border-t-2 border-cyan-500/50 hidden opacity-50"></div>
            <div class="pulse-effect" style="width: 100%; height: 100%;"></div>
            <div class="pulse-effect" style="width: 100%; height: 100%; animation-delay: 1s;"></div>
        </div>

        <div class="text-center mb-10">
            <h2 class="text-3xl orbitron font-bold text-white mb-2 tracking-widest">NEURAL LIVE</h2>
            <p id="live-status" class="text-cyan-500 text-xs orbitron tracking-[0.4em] animate-pulse">LISTENING...</p>
        </div>

        <!-- Dynamic Waveform -->
        <div class="flex items-end gap-1.5 h-12 mb-10" id="waveform">
            <div class="wave-bar" style="animation-delay: 0.1s"></div>
            <div class="wave-bar" style="animation-delay: 0.3s"></div>
            <div class="wave-bar" style="animation-delay: 0.2s"></div>
            <div class="wave-bar" style="animation-delay: 0.4s"></div>
            <div class="wave-bar" style="animation-delay: 0.3s"></div>
        </div>

        <div class="flex gap-10">
            <button onclick="toggleMic()" id="live-mic" class="w-16 h-16 rounded-full glass border border-cyan-500/30 flex items-center justify-center text-cyan-400"><i data-lucide="mic" class="w-8 h-8"></i></button>
            <button onclick="processVision()" class="w-16 h-16 rounded-full bg-cyan-500 text-black flex items-center justify-center shadow-lg"><i data-lucide="scan" class="w-8 h-8"></i></button>
        </div>
    </div>

    <canvas id="hidden-canvas" class="hidden"></canvas>

    <script>
        lucide.createIcons();
        
        const chatContainer = document.getElementById('chat-container');
        const userInput = document.getElementById('user-input');
        const apiKey = document.getElementById('api-key');
        const liveOverlay = document.getElementById('live-overlay');
        const liveVideo = document.getElementById('live-video');
        const canvas = document.getElementById('hidden-canvas');
        const liveStatus = document.getElementById('live-status');

        let isLive = false;
        let isSpeaking = false;
        let recognition;
        const synth = window.speechSynthesis;

        // --- Auth Setup ---
        if(localStorage.getItem('jx_live_key')) {
            apiKey.value = localStorage.getItem('jx_live_key');
            toggleUI(true);
        }

        function saveAuth() {
            if(apiKey.value.length < 10) return alert("Invalid Key");
            localStorage.setItem('jx_live_key', apiKey.value);
            toggleUI(true);
            speak("Uplink successful. Neural live systems are ready.");
        }

        function toggleUI(ready) {
            document.getElementById('auth-section').classList.toggle('hidden', ready);
            document.getElementById('input-section').classList.toggle('hidden', !ready);
        }

        // --- Human Voice Engine ---
        function speak(text) {
            synth.cancel();
            
            // Filter: No emojis or symbols for voice
            let cleanText = text.replace(/[*#`_~>]/g, '')
                                .replace(/[\u{1F600}-\u{1F64F}\u{1F300}-\u{1F5FF}\u{1F680}-\u{1F6FF}]/gu, '');

            setTimeout(() => {
                const utterance = new SpeechSynthesisUtterance(cleanText);
                const voices = synth.getVoices();
                const isBengali = /[\u0980-\u09FF]/.test(text);
                
                utterance.voice = voices.find(v => isBengali ? v.lang.includes('bn') : v.lang.includes('en-IN')) || voices[0];
                utterance.pitch = 0.95;
                utterance.rate = 1.05;

                utterance.onstart = () => { isSpeaking = true; liveStatus.textContent = "JARVIS SPEAKING..."; };
                utterance.onend = () => { isSpeaking = false; liveStatus.textContent = "LISTENING..."; if(isLive) startVoiceRec(); };
                
                synth.speak(utterance);
            }, 500);
        }

        // --- Live Mode & Vision Core ---
        async function enterLiveMode() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "environment" }, audio: true });
                liveVideo.srcObject = stream;
                liveOverlay.classList.remove('hidden');
                document.body.classList.add('live-active');
                isLive = true;
                speak("Live vision initialized. I am watching, sir.");
                startVoiceRec();
            } catch(e) { alert("Camera/Mic access required for Live Mode."); }
        }

        function exitLiveMode() {
            liveVideo.srcObject.getTracks().forEach(t => t.stop());
            liveOverlay.classList.add('hidden');
            document.body.classList.remove('live-active');
            isLive = false;
            recognition.stop();
        }

        async function processVision(voicePrompt = "What do you see?") {
            if(!isLive) return;
            liveStatus.textContent = "ANALYZING...";
            
            canvas.width = liveVideo.videoWidth;
            canvas.height = liveVideo.videoHeight;
            canvas.getContext('2d').drawImage(liveVideo, 0, 0);
            const imageData = canvas.toDataURL('image/jpeg', 0.5).split(',')[1];

            try {
                const res = await fetch("https://openrouter.ai/api/v1/chat/completions", {
                    method: "POST",
                    headers: { "Authorization": `Bearer ${apiKey.value}`, "Content-Type": "application/json" },
                    body: JSON.stringify({
                        model: "google/gemini-pro-1.5-exp",
                        messages: [{
                            role: "user",
                            content: [
                                { type: "text", text: `The user says: "${voicePrompt}". Analyze this live frame and respond in their language (Bangla or English). Be brief and human-like.` },
                                { type: "image_url", image_url: { url: `data:image/jpeg;base64,${imageData}` } }
                            ]
                        }]
                    })
                });
                const data = await res.json();
                const reply = data.choices[0].message.content;
                addMessage('JARVIS', reply, false);
                speak(reply);
            } catch(e) { speak("Neural vision uplink lost."); }
        }

        // --- Speech Recognition ---
        if('webkitSpeechRecognition' in window) {
            recognition = new webkitSpeechRecognition();
            recognition.continuous = false;
            recognition.interimResults = false;
            
            recognition.onresult = (e) => {
                const txt = e.results[0][0].transcript;
                if(isLive) {
                    if(txt.toLowerCase().includes('what') || txt.toLowerCase().includes('দেখো') || txt.toLowerCase().includes('কি')) {
                        processVision(txt);
                    } else {
                        handleSend(txt);
                    }
                } else {
                    userInput.value = txt;
                    handleSend();
                }
            };
        }

        function startVoiceRec() {
            if(!isSpeaking) try { recognition.start(); } catch(e) {}
        }

        // --- Chat Processing ---
        async function handleSend(manualTxt = null) {
            const prompt = manualTxt || userInput.value.trim();
            if(!prompt) return;

            addMessage('USER', prompt, true);
            if(!manualTxt) userInput.value = "";

            try {
                const res = await fetch("https://openrouter.ai/api/v1/chat/completions", {
                    method: "POST",
                    headers: { "Authorization": `Bearer ${apiKey.value}`, "Content-Type": "application/json" },
                    body: JSON.stringify({
                        model: "openai/gpt-4o-mini",
                        messages: [
                            { role: "system", content: "You are JARVIS X. Multilingual (English/Bengali). Reply in the user's language. Stay sharp, calm, and professional. You are in a neural link session." },
                            { role: "user", content: prompt }
                        ]
                    })
                });
                const data = await res.json();
                const reply = data.choices[0].message.content;
                addMessage('JARVIS', reply, false);
                speak(reply);
            } catch(e) { addMessage('SYS', 'Connection Error'); }
        }

        function addMessage(who, msg, isUser) {
            const div = document.createElement('div');
            div.className = `flex gap-4 max-w-2xl animate-fade-in ${isUser ? 'ml-auto flex-row-reverse' : ''}`;
            
            const icon = isUser ? 'user' : 'bot';
            const color = isUser ? 'gray-700' : 'cyan-900/20';

            div.innerHTML = `
                <div class="w-10 h-10 rounded-xl bg-${color} border border-cyan-500/20 flex items-center justify-center shrink-0">
                    <i data-lucide="${icon}" class="w-6 h-6 text-cyan-400"></i>
                </div>
                <div class="glass p-4 rounded-3xl ${isUser ? 'rounded-tr-none border-cyan-500/20' : 'rounded-tl-none border-white/5'} text-sm leading-relaxed">
                    ${msg}
                </div>
            `;
            chatContainer.appendChild(div);
            lucide.createIcons();
            chatContainer.scrollTop = chatContainer.scrollHeight;
        }

        // Battery System
        if(navigator.getBattery) {
            navigator.getBattery().then(b => {
                const up = () => document.getElementById('sys-pwr').textContent = `PWR: ${Math.round(b.level*100)}%`;
                b.onlevelchange = up; up();
            });
        }
    </script>
</body>
</html>