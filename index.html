<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>JARVIS X | MASTER CORE</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://unpkg.com/lucide@latest"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jspdf/2.5.1/jspdf.umd.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/tesseract.js@5/dist/tesseract.min.js"></script>
    
    <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@400;700&family=JetBrains+Mono&display=swap" rel="stylesheet">
    <style>
        :root { --neon: #00f2ff; --warn: #ff004c; --bg: #020406; --glass: rgba(10, 12, 16, 0.9); }
        body { font-family: 'JetBrains Mono', monospace; background: var(--bg); color: #e2e8f0; overflow: hidden; height: 100vh; }
        .orbitron { font-family: 'Orbitron', sans-serif; }
        .glass { background: var(--glass); backdrop-filter: blur(20px); border: 1px solid rgba(255, 255, 255, 0.08); }
        .neon-glow { border: 1px solid var(--neon); box-shadow: 0 0 15px rgba(0, 242, 255, 0.2); }
        
        /* Animations */
        @keyframes scan { 0% { top: 0; } 100% { top: 100%; } }
        .scanner { position: absolute; width: 100%; height: 2px; background: var(--neon); animation: scan 3s linear infinite; opacity: 0.5; }
        
        .speaking-active { animation: pulse 0.5s infinite alternate; }
        @keyframes pulse { from { transform: scale(1); box-shadow: 0 0 10px var(--neon); } to { transform: scale(1.1); box-shadow: 0 0 30px var(--neon); } }

        .tool-tab { display: none; }
        .tool-tab.active { display: block; animation: fadeIn 0.3s ease; }
        @keyframes fadeIn { from { opacity: 0; transform: translateY(10px); } to { opacity: 1; transform: translateY(0); } }
        
        #webcam { transform: scaleX(-1); }
    </style>
</head>
<body class="flex flex-col">

    <header class="h-14 glass border-b border-white/5 flex items-center justify-between px-4 z-50">
        <div class="flex items-center gap-3">
            <div class="w-7 h-7 bg-cyan-600 flex items-center justify-center rounded">
                <i data-lucide="shield-check" class="w-4 h-4 text-black"></i>
            </div>
            <h1 class="text-sm font-bold orbitron text-cyan-400 tracking-widest">JARVIS X</h1>
        </div>
        <div class="flex items-center gap-4 text-[10px] orbitron text-cyan-500">
            <span id="sys-load">CPU: 12% RAM: 45%</span>
            <span id="pwr-stat">PWR: 100%</span>
        </div>
    </header>

    <main class="flex-1 flex flex-col md:flex-row overflow-hidden relative">
        
        <video id="webcam" class="absolute inset-0 w-full h-full object-cover opacity-20 pointer-events-none" autoplay playsinline></video>
        <div class="absolute inset-0 bg-gradient-to-b from-black/60 via-transparent to-black/80 pointer-events-none"></div>

        <aside class="w-full md:w-80 glass border-r border-white/5 p-4 flex flex-col z-40">
            <div class="flex gap-2 mb-4 overflow-x-auto pb-2">
                <button onclick="showTab('automation')" class="px-3 py-1 text-[10px] orbitron border border-cyan-500/30 rounded hover:bg-cyan-500/10">AUTOMATION</button>
                <button onclick="showTab('system')" class="px-3 py-1 text-[10px] orbitron border border-cyan-500/30 rounded hover:bg-cyan-500/10">SYSTEM</button>
                <button onclick="showTab('tools')" class="px-3 py-1 text-[10px] orbitron border border-cyan-500/30 rounded hover:bg-cyan-500/10">TOOLS</button>
            </div>

            <div id="automation" class="tool-tab active space-y-3">
                <div class="p-3 bg-white/5 rounded-lg border border-white/10">
                    <p class="text-[10px] text-cyan-500 orbitron mb-2">WhatsApp Control</p>
                    <div class="flex flex-wrap gap-2">
                        <button onclick="waAction('msg')" class="bg-cyan-900/40 p-2 rounded text-[10px] flex items-center gap-2"><i data-lucide="message-square" class="w-3 h-3"></i> MSG</button>
                        <button onclick="waAction('call')" class="bg-cyan-900/40 p-2 rounded text-[10px] flex items-center gap-2"><i data-lucide="phone" class="w-3 h-3"></i> CALL</button>
                    </div>
                </div>
            </div>

            <div id="system" class="tool-tab space-y-3">
                <div class="p-3 bg-white/5 rounded-lg border border-white/10 text-[10px]">
                    <p class="text-cyan-500 orbitron mb-2">Device Info</p>
                    <p>Core Status: Online</p>
                    <p>OS: Android/Vivo Virtualized</p>
                </div>
            </div>

            <div id="tools" class="tool-tab space-y-3">
                <div class="p-3 bg-white/5 rounded-lg border border-white/10 text-[10px]">
                    <label class="block w-full bg-cyan-500 text-black font-bold py-2 text-center rounded cursor-pointer mb-2">
                        SCAN IMAGE (OCR)
                        <input type="file" id="ocr-upload" class="hidden" accept="image/*" onchange="performOCR(this)">
                    </label>
                    <button onclick="generatePDF()" class="w-full bg-white/10 py-2 rounded">DOWNLOAD SESSION PDF</button>
                </div>
            </div>
        </aside>

        <section class="flex-1 flex flex-col relative">
            <div id="chat-flow" class="flex-1 overflow-y-auto p-4 md:p-10 space-y-6 pb-40">
                <div class="flex gap-4 max-w-2xl">
                    <div class="w-10 h-10 rounded-xl bg-cyan-900/20 border border-cyan-500/20 flex items-center justify-center shrink-0">
                        <i data-lucide="bot" class="w-6 h-6 text-cyan-400"></i>
                    </div>
                    <div class="glass p-4 rounded-2xl rounded-tl-none text-sm border-white/5">
                        System encrypted. Waiting for Security Key to initialize neural link, sir.
                    </div>
                </div>
            </div>

            <div class="absolute bottom-0 w-full p-4 md:p-8 glass border-t border-white/5">
                <div id="auth-box" class="max-w-4xl mx-auto flex gap-2 mb-2">
                    <input type="password" id="api-key" placeholder="Paste OpenRouter or Gemini Key..." class="flex-1 bg-black/50 border border-white/10 rounded-xl px-4 py-3 text-xs outline-none focus:border-cyan-500 text-cyan-400">
                    <button onclick="initializeJarvis()" class="px-6 py-3 bg-cyan-600 text-black font-bold text-xs orbitron rounded-xl">CHECK-IN</button>
                </div>
                
                <div id="input-box" class="max-w-4xl mx-auto hidden relative">
                    <div class="flex items-center gap-3 glass p-2 rounded-2xl border-white/10 neon-glow">
                        <button onclick="toggleVision()" class="p-3 text-gray-400 hover:text-cyan-400">
                            <i data-lucide="eye" class="w-6 h-6"></i>
                        </button>
                        <textarea id="user-input" rows="1" placeholder="Enter command..." class="flex-1 bg-transparent border-none outline-none text-sm py-3 text-white resize-none"></textarea>
                        <button onclick="startVoice()" class="p-3 text-gray-400 hover:text-cyan-400"><i data-lucide="mic" class="w-6 h-6"></i></button>
                        <button onclick="handleAction()" class="p-3 bg-cyan-500 text-black rounded-xl"><i data-lucide="send" class="w-6 h-6"></i></button>
                    </div>
                </div>
            </div>
        </section>
    </main>

    <div id="vision-hud" class="fixed inset-0 z-[100] bg-black hidden flex flex-col items-center justify-center">
        <div class="absolute top-10 flex flex-col items-center">
            <h2 class="orbitron text-cyan-400 text-2xl tracking-[1em]">VISION ACTIVE</h2>
            <div class="scanner mt-4"></div>
        </div>
        <div class="relative w-64 h-64 border-4 border-cyan-500/20 rounded-full flex items-center justify-center">
            <div id="arc-reactor" class="w-24 h-24 bg-cyan-500 rounded-full shadow-[0_0_60px_rgba(0,242,255,1)]"></div>
        </div>
        <button onclick="toggleVision()" class="mt-20 border border-red-500 text-red-500 px-10 py-2 orbitron text-xs rounded-full">TERMINATE VISION</button>
    </div>

    <script>
        lucide.createIcons();
        const chatFlow = document.getElementById('chat-flow');
        const userInput = document.getElementById('user-input');
        const apiKeyInput = document.getElementById('api-key');
        const webcam = document.getElementById('webcam');
        const arcReactor = document.getElementById('arc-reactor');

        let synth = window.speechSynthesis;
        let recognition;

        // --- Voice Logic ---
        function speak(text) {
            synth.cancel();
            const utterance = new SpeechSynthesisUtterance(text);
            const voices = synth.getVoices();
            // Try to find a good English or Bengali voice
            utterance.voice = voices.find(v => v.lang.includes('bn-IN')) || voices.find(v => v.lang.includes('en-IN')) || voices[0];
            utterance.rate = 1.1;
            utterance.onstart = () => arcReactor.classList.add('speaking-active');
            utterance.onend = () => arcReactor.classList.remove('speaking-active');
            synth.speak(utterance);
        }

        // --- OCR & PDF ---
        async function performOCR(input) {
            if(!input.files[0]) return;
            addLog('SYSTEM', 'Scanning document...');
            const { data: { text } } = await Tesseract.recognize(input.files[0], 'eng+ben');
            addLog('JARVIS', `OCR Extraction: ${text}`);
            speak("Scanning complete, sir. Text is on your terminal.");
        }

        function generatePDF() {
            const doc = new jspdf.jsPDF();
            doc.text("JARVIS X SESSION LOG", 10, 10);
            let y = 20;
            document.querySelectorAll('.chat-msg').forEach(m => {
                doc.text(m.innerText.substring(0, 50), 10, y);
                y += 10;
            });
            doc.save('session.pdf');
            speak("PDF compiled and saved.");
        }

        // --- Core Action ---
        async function handleAction() {
            const prompt = userInput.value.trim();
            if(!prompt) return;
            addLog('USER', prompt, true);
            userInput.value = "";

            try {
                // If you use OpenRouter
                const response = await fetch("https://openrouter.ai/api/v1/chat/completions", {
                    method: "POST",
                    headers: {
                        "Authorization": `Bearer ${apiKeyInput.value}`,
                        "Content-Type": "application/json"
                    },
                    body: JSON.stringify({
                        model: "google/gemini-pro-1.5",
                        messages: [{ role: "system", content: "You are JARVIS X. Intelligent and concise. Respond in Bengali or English based on user." }, { role: "user", content: prompt }]
                    })
                });
                const data = await response.json();
                const reply = data.choices[0].message.content;
                addLog('JARVIS', reply);
                speak(reply);
            } catch(e) {
                addLog('JARVIS', "Neural link error. Check API key or connection.");
            }
        }

        // --- Helpers ---
        function initializeJarvis() {
            if(apiKeyInput.value.length < 10) return alert("Valid API key required.");
            document.getElementById('auth-box').classList.add('hidden');
            document.getElementById('input-box').classList.remove('hidden');
            addLog('JARVIS', "Neural link synchronized. Welcome back, sir.");
            speak("Welcome back, sir. Systems are online.");
            navigator.mediaDevices.getUserMedia({ video: true }).then(s => webcam.srcObject = s);
        }

        function addLog(who, msg, isUser) {
            const div = document.createElement('div');
            div.className = `flex gap-4 ${isUser ? 'flex-row-reverse' : ''}`;
            div.innerHTML = `
                <div class="w-8 h-8 rounded bg-cyan-900/30 flex items-center justify-center border border-cyan-500/20"><i data-lucide="${isUser?'user':'bot'}" class="w-4 h-4 text-cyan-400"></i></div>
                <div class="chat-msg glass p-3 rounded-lg text-xs border-white/5 max-w-[80%]">${msg}</div>
            `;
            chatFlow.appendChild(div);
            lucide.createIcons();
            chatFlow.scrollTop = chatFlow.scrollHeight;
        }

        function showTab(id) {
            document.querySelectorAll('.tool-tab').forEach(t => t.classList.remove('active'));
            document.getElementById(id).classList.add('active');
        }

        function toggleVision() { document.getElementById('vision-hud').classList.toggle('hidden'); }

        function waAction(t) { 
            const n = prompt("Target Number:");
            if(n) window.open(t==='msg' ? `https://wa.me/${n}` : `tel:${n}`);
        }

        // Voice
        if('webkitSpeechRecognition' in window) {
            recognition = new webkitSpeechRecognition();
            recognition.onresult = (e) => {
                userInput.value = e.results[0][0].transcript;
                handleAction();
            };
        }
        function startVoice() { recognition.start(); }
    </script>
</body>
</html>
    <main class="flex-1 relative flex flex-col overflow-hidden">
        
        <!-- Chat Flow -->
        <div id="chat-container" class="flex-1 overflow-y-auto p-4 md:p-10 space-y-6 scroll-smooth pb-32">
            <div class="flex gap-4 max-w-2xl">
                <div class="w-10 h-10 rounded-xl bg-cyan-900/20 border border-cyan-500/20 flex items-center justify-center shrink-0">
                    <i data-lucide="bot" class="w-6 h-6 text-cyan-400"></i>
                </div>
                <div class="glass p-4 rounded-2xl rounded-tl-none text-sm border-white/5 shadow-xl">
                    Greetings, sir. Neural link is active. Shall we initiate live vision?
                </div>
            </div>
        </div>

        <!-- Floating Live Vision Button -->
        <button onclick="enterLiveMode()" id="live-btn" class="fixed bottom-28 right-6 w-16 h-16 bg-cyan-500 text-black rounded-full shadow-[0_0_30px_rgba(0,242,255,0.4)] flex items-center justify-center z-50 hover:scale-110 transition-transform">
            <i data-lucide="eye" class="w-8 h-8"></i>
        </button>

        <!-- Input Section -->
        <div class="absolute bottom-0 w-full p-4 md:p-8 glass border-t border-white/5 z-40">
            <div id="auth-section" class="max-w-4xl mx-auto flex gap-2 mb-2">
                <input type="password" id="api-key" placeholder="Enter OpenRouter API Key..." class="flex-1 bg-black/50 border border-white/10 rounded-xl px-4 py-3 text-xs outline-none focus:border-cyan-500">
                <button onclick="saveAuth()" class="px-6 py-3 bg-cyan-600 text-black font-bold text-xs orbitron rounded-xl">CHECK-IN</button>
            </div>

            <div id="input-section" class="max-w-4xl mx-auto relative hidden">
                <div class="flex items-center gap-2 glass p-2 rounded-2xl border-white/10 neon-glow">
                    <textarea id="user-input" rows="1" placeholder="Type or use voice..." class="flex-1 bg-transparent border-none outline-none text-sm p-3 resize-none max-h-32"></textarea>
                    <button onclick="startVoiceRec()" class="p-3 text-gray-400 hover:text-cyan-400"><i data-lucide="mic" class="w-6 h-6"></i></button>
                    <button onclick="handleSend()" class="p-3 bg-cyan-500 text-black rounded-xl hover:bg-cyan-300"><i data-lucide="send" class="w-6 h-6"></i></button>
                </div>
            </div>
        </div>
    </main>

    <!-- Gemini Live Style Full Overlay -->
    <div id="live-overlay" class="fixed inset-0 z-[100] bg-black hidden flex-col items-center justify-center p-6">
        <button onclick="exitLiveMode()" class="absolute top-6 right-6 text-gray-500 hover:text-white z-50"><i data-lucide="x-circle" class="w-10 h-10"></i></button>

        <!-- Live Camera Circle -->
        <div class="relative w-72 h-72 md:w-96 md:h-96 rounded-full overflow-hidden border-4 border-cyan-500/30 neon-glow mb-8 flex items-center justify-center">
            <video id="live-video" class="absolute inset-0" autoplay playsinline muted></video>
            <div id="vision-scanner" class="absolute inset-0 pointer-events-none border-t-2 border-cyan-500/50 hidden opacity-50"></div>
            <div class="pulse-effect" style="width: 100%; height: 100%;"></div>
            <div class="pulse-effect" style="width: 100%; height: 100%; animation-delay: 1s;"></div>
        </div>

        <div class="text-center mb-6">
            <h2 class="text-2xl md:text-3xl orbitron font-bold text-white mb-2 tracking-widest">NEURAL LIVE</h2>
            <p id="live-status" class="text-cyan-500 text-xs orbitron tracking-[0.4em] animate-pulse">LISTENING...</p>
        </div>

        <!-- Dynamic Waveform -->
        <div class="flex items-end gap-1.5 h-12 mb-6" id="waveform">
            <div class="wave-bar" style="animation-delay: 0.1s"></div>
            <div class="wave-bar" style="animation-delay: 0.3s"></div>
            <div class="wave-bar" style="animation-delay: 0.2s"></div>
            <div class="wave-bar" style="animation-delay: 0.4s"></div>
            <div class="wave-bar" style="animation-delay: 0.3s"></div>
        </div>

        <!-- Live Controls with Labels -->
        <div class="flex gap-8 md:gap-10">
            <div class="flex flex-col items-center">
                <button onclick="toggleMic()" id="live-mic" class="w-14 h-14 md:w-16 md:h-16 rounded-full glass border border-cyan-500/30 flex items-center justify-center text-cyan-400"><i data-lucide="mic" class="w-7 h-7 md:w-8 md:h-8"></i></button>
                <span class="control-label">VOICE</span>
            </div>
            <div class="flex flex-col items-center">
                <button onclick="processVision()" class="w-14 h-14 md:w-16 md:h-16 rounded-full bg-cyan-500 text-black flex items-center justify-center shadow-lg"><i data-lucide="scan" class="w-7 h-7 md:w-8 md:h-8"></i></button>
                <span class="control-label">SCAN</span>
            </div>
            <div class="flex flex-col items-center">
                <button onclick="switchCamera()" id="cam-switch" class="w-14 h-14 md:w-16 md:h-16 rounded-full glass border border-cyan-500/30 flex items-center justify-center text-cyan-400"><i data-lucide="refresh-cw" class="w-7 h-7 md:w-8 md:h-8"></i></button>
                <span class="control-label">CAMERA</span>
            </div>
        </div>
    </div>

    <canvas id="hidden-canvas" class="hidden"></canvas>

    <script>
        lucide.createIcons();

        const chatContainer = document.getElementById('chat-container');
        const userInput = document.getElementById('user-input');
        const apiKey = document.getElementById('api-key');
        const liveOverlay = document.getElementById('live-overlay');
        const liveVideo = document.getElementById('live-video');
        const canvas = document.getElementById('hidden-canvas');
        const liveStatus = document.getElementById('live-status');

        let isLive = false;
        let isSpeaking = false;
        let recognition;
        let currentFacing = "environment";
        let currentStream = null;
        const synth = window.speechSynthesis;

        // --- Auth Setup ---
        if(localStorage.getItem('jx_live_key')) {
            apiKey.value = localStorage.getItem('jx_live_key');
            toggleUI(true);
        }

        function saveAuth() {
            if(apiKey.value.length < 10) return alert("Invalid Key");
            localStorage.setItem('jx_live_key', apiKey.value);
            toggleUI(true);
            speak("Uplink successful. Neural live systems are ready.");
        }

        function toggleUI(ready) {
            document.getElementById('auth-section').classList.toggle('hidden', ready);
            document.getElementById('input-section').classList.toggle('hidden', !ready);
        }

        // --- Human Voice Engine ---
        function speak(text) {
            synth.cancel();

            // Filter: No emojis or symbols for voice
            let cleanText = text.replace(/[*#`_~>]/g, '')
                                .replace(/[\u{1F600}-\u{1F64F}\u{1F300}-\u{1F5FF}\u{1F680}-\u{1F6FF}]/gu, '');

            setTimeout(() => {
                const utterance = new SpeechSynthesisUtterance(cleanText);
                const voices = synth.getVoices();
                const isBengali = /[\u0980-\u09FF]/.test(text);

                utterance.voice = voices.find(v => isBengali ? v.lang.includes('bn') : v.lang.includes('en-IN')) || voices[0];
                utterance.pitch = 0.95;
                utterance.rate = 1.05;

                utterance.onstart = () => { isSpeaking = true; liveStatus.textContent = "JARVIS SPEAKING..."; };
                utterance.onend = () => { isSpeaking = false; liveStatus.textContent = "LISTENING..."; if(isLive) startVoiceRec(); };

                synth.speak(utterance);
            }, 500);
        }

        // --- Live Mode & Vision Core ---
        async function startCamera(facing) {
            if(currentStream) currentStream.getTracks().forEach(t => t.stop());
            const stream = await navigator.mediaDevices.getUserMedia({
                video: { facingMode: facing, width: { ideal: 1280 }, height: { ideal: 720 } },
                audio: true
            });
            liveVideo.srcObject = stream;
            currentStream = stream;
            return stream;
        }

        async function enterLiveMode() {
            try {
                await startCamera(currentFacing);
                liveOverlay.classList.remove('hidden');
                liveOverlay.style.display = 'flex';
                document.body.classList.add('live-active');
                isLive = true;
                speak("Live vision initialized. I am watching, sir.");
                startVoiceRec();
            } catch(e) { alert("Camera/Mic access required for Live Mode."); }
        }

        function exitLiveMode() {
            if(currentStream) currentStream.getTracks().forEach(t => t.stop());
            currentStream = null;
            liveOverlay.classList.add('hidden');
            liveOverlay.style.display = 'none';
            document.body.classList.remove('live-active');
            isLive = false;
            if(recognition) try { recognition.stop(); } catch(e) {}
        }

        async function switchCamera() {
            if(!isLive) return;
            currentFacing = currentFacing === "environment" ? "user" : "environment";
            try {
                await startCamera(currentFacing);
            } catch(e) {
                currentFacing = currentFacing === "environment" ? "user" : "environment";
            }
        }

        async function processVision(voicePrompt = "What do you see?") {
            if(!isLive) return;
            liveStatus.textContent = "ANALYZING...";

            canvas.width = liveVideo.videoWidth;
            canvas.height = liveVideo.videoHeight;
            canvas.getContext('2d').drawImage(liveVideo, 0, 0);
            const imageData = canvas.toDataURL('image/jpeg', 0.5).split(',')[1];

            try {
                const res = await fetch("https://openrouter.ai/api/v1/chat/completions", {
                    method: "POST",
                    headers: { "Authorization": `Bearer ${apiKey.value}`, "Content-Type": "application/json" },
                    body: JSON.stringify({
                        model: "google/gemini-pro-1.5-exp",
                        messages: [{
                            role: "user",
                            content: [
                                { type: "text", text: `The user says: "${voicePrompt}". Analyze this live frame and respond in their language (Bangla or English). Be brief and human-like.` },
                                { type: "image_url", image_url: { url: `data:image/jpeg;base64,${imageData}` } }
                            ]
                        }]
                    })
                });
                const data = await res.json();
                const reply = data.choices[0].message.content;
                addMessage('JARVIS', reply, false);
                speak(reply);
            } catch(e) { speak("Neural vision uplink lost."); }
        }

        // --- Speech Recognition (Android + Chrome) ---
        const SpeechRecAPI = window.SpeechRecognition || window.webkitSpeechRecognition;
        if(SpeechRecAPI) {
            recognition = new SpeechRecAPI();
            recognition.continuous = false;
            recognition.interimResults = false;
            recognition.lang = 'bn-BD';

            recognition.onstart = () => {
                document.getElementById('live-mic').classList.add('voice-active');
            };

            recognition.onend = () => {
                document.getElementById('live-mic').classList.remove('voice-active');
            };

            recognition.onerror = (e) => {
                document.getElementById('live-mic').classList.remove('voice-active');
                if(isLive && e.error !== 'aborted' && e.error !== 'no-speech') {
                    setTimeout(() => startVoiceRec(), 1000);
                }
            };

            recognition.onresult = (e) => {
                const txt = e.results[0][0].transcript;
                if(isLive) {
                    if(txt.toLowerCase().includes('what') || txt.toLowerCase().includes('দেখো') || txt.toLowerCase().includes('কি')) {
                        processVision(txt);
                    } else {
                        handleSend(txt);
                    }
                } else {
                    userInput.value = txt;
                    handleSend();
                }
            };
        }

        function startVoiceRec() {
            if(!isSpeaking && recognition) try { recognition.start(); } catch(e) {}
        }

        function toggleMic() {
            if(isSpeaking) {
                synth.cancel();
                isSpeaking = false;
                liveStatus.textContent = "LISTENING...";
                startVoiceRec();
            } else {
                startVoiceRec();
            }
        }

        // --- Chat Processing ---
        async function handleSend(manualTxt = null) {
            const prompt = manualTxt || userInput.value.trim();
            if(!prompt) return;

            addMessage('USER', prompt, true);
            if(!manualTxt) userInput.value = "";

            try {
                const res = await fetch("https://openrouter.ai/api/v1/chat/completions", {
                    method: "POST",
                    headers: { "Authorization": `Bearer ${apiKey.value}`, "Content-Type": "application/json" },
                    body: JSON.stringify({
                        model: "openai/gpt-4o-mini",
                        messages: [
                            { role: "system", content: "You are JARVIS X. Multilingual (English/Bengali). Reply in the user's language. Stay sharp, calm, and professional. You are in a neural link session." },
                            { role: "user", content: prompt }
                        ]
                    })
                });
                const data = await res.json();
                const reply = data.choices[0].message.content;
                addMessage('JARVIS', reply, false);
                speak(reply);
            } catch(e) { addMessage('SYS', 'Connection Error'); }
        }

        function addMessage(who, msg, isUser) {
            const div = document.createElement('div');
            div.className = `flex gap-4 max-w-2xl animate-fade-in ${isUser ? 'ml-auto flex-row-reverse' : ''}`;

            const icon = isUser ? 'user' : 'bot';
            const color = isUser ? 'gray-700' : 'cyan-900/20';

            div.innerHTML = `
                <div class="w-10 h-10 rounded-xl bg-${color} border border-cyan-500/20 flex items-center justify-center shrink-0">
                    <i data-lucide="${icon}" class="w-6 h-6 text-cyan-400"></i>
                </div>
                <div class="glass p-4 rounded-3xl ${isUser ? 'rounded-tr-none border-cyan-500/20' : 'rounded-tl-none border-white/5'} text-sm leading-relaxed">
                    ${msg}
                </div>
            `;
            chatContainer.appendChild(div);
            lucide.createIcons();
            chatContainer.scrollTop = chatContainer.scrollHeight;
        }

        // Battery System
        if(navigator.getBattery) {
            navigator.getBattery().then(b => {
                const up = () => document.getElementById('sys-pwr').textContent = `PWR: ${Math.round(b.level*100)}%`;
                b.onlevelchange = up; up();
            });
        }

        // Pre-load voices for Android
        synth.onvoiceschanged = () => synth.getVoices();
    </script>
</body>
</html>
